{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test import test\n",
    "from options.options import Options\n",
    "from copy import deepcopy\n",
    "import data\n",
    "\n",
    "org_opt = Options('options/test_options.yaml')\n",
    "org_opt.initialize()\n",
    "org_opt.train_mode = 'GAN'\n",
    "org_opt.how_many = 8\n",
    "org_opt.batch_size = org_opt.how_many\n",
    "dataloader, dataset = data.create_dataloader(org_opt, 'train')\n",
    "mesh_files = dataset.mesh_paths[:org_opt.how_many]\n",
    "\n",
    "for exp in range(org_opt.number_of_experiments-1,-1,-1):\n",
    "    opt = deepcopy(org_opt)\n",
    "    exp_str = '(exp'+str(exp+1)+')'\n",
    "    if opt.number_of_experiments<=1:\n",
    "        exp_str = ''\n",
    "    opt.set_experiment(exp)\n",
    "        \n",
    "    for inst in range(org_opt.number_of_instances):\n",
    "        inst_str = '(inst'+str(inst+1)+')'\n",
    "        if opt.number_of_instances==1:\n",
    "            inst_str = ''\n",
    "        opt.name = org_opt.name+exp_str+inst_str\n",
    "\n",
    "        to_print = '***************************************************************************************' + \\\n",
    "                   '\\n    Testing results of ' + opt.name + '\\n' + \\\n",
    "                   '***************************************************************************************'\n",
    "        print(to_print)\n",
    "        exp = test(opt, True)\n",
    "        exp.run_test(mesh_files, [3,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.slice_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data\n",
    "from test_all import test\n",
    "from options.options import Options\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_opt = Options('options/test_options.yaml')\n",
    "org_opt.initialize()\n",
    "org_opt.train_mode = 'GAN'\n",
    "org_opt.batch_size = org_opt.how_many\n",
    "dataloader, dataset = data.create_dataloader(org_opt)\n",
    "\n",
    "mesh_files = dataset.mesh_paths[:org_opt.how_many]\n",
    "data = next(iter(dataloader))\n",
    "patches = data['mesh_slices'][:org_opt.how_many,0]\n",
    "\n",
    "opt = deepcopy(org_opt)\n",
    "\n",
    "exp = 8\n",
    "inst = 1\n",
    "\n",
    "# load the dataset\n",
    "opt = deepcopy(org_opt)\n",
    "opt.name += '(exp'+str(exp)+')'#(inst'+str(inst)+')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = test(opt, True)\n",
    "t.run_test(mesh_files, [10,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,2,3,4]\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from functools import partial\n",
    "from copy import deepcopy\n",
    "\n",
    "from util.util import mkdir\n",
    "from pathlib import Path\n",
    "import imageio\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "from util.mesh_handler import *\n",
    "from util.util import tensorize_dict\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import data\n",
    "from options.options import Options\n",
    "from models.pix2pix_model import Pix2PixModel\n",
    "\n",
    "from util.mesh_handler import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,2,3]+[4,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_patches(vox, k, d, padding=True):\n",
    "    x = torch.Tensor(vox)\n",
    "    kc, kh, kw = k  # kernel size\n",
    "    dc, dh, dw = d  # stride\n",
    "\n",
    "    # Pad to multiples of 32\n",
    "    if padding:\n",
    "        x = F.pad(x, (kw//2, kw//2,\n",
    "                      kh//2, kh//2,\n",
    "                      kc//2, kc//2))\n",
    "\n",
    "    patches = x.unfold(1, kc, dc).unfold(2, kh, dh).unfold(3, kw, dw)\n",
    "    patches = patches.contiguous().view(len(vox),-1,1,kc,kh,kw)\n",
    "    return patches\n",
    "\n",
    "def no_padding(input, sz, dim='3D'):\n",
    "    beg = np.asarray(sz)//2\n",
    "    end = -1*beg.copy()\n",
    "    end[end==0] = 1\n",
    "    \n",
    "    return input[:,:,beg[0]:end[0], beg[1]:end[1], beg[2]:end[2]]\n",
    "\n",
    "def generate(vox, sigmas, background, p_blobs, powers, frames):\n",
    "    out = np.zeros([len(powers),1, *vox.shape])\n",
    "    blur = blur_vox(vox,sigmas,background)\n",
    "    \n",
    "    for i in range(len(powers)): \n",
    "        fake = add_blobs(np.copy(blur), p_blobs, background)\n",
    "        fake = add_poisson_noise(fake, powers[i], frames[i])\n",
    "        out[i] = fake\n",
    "        \n",
    "    return torch.Tensor(out), blur>background\n",
    "\n",
    "def test(model, vox, powers, frames):\n",
    "    n_samples = vox.shape[1]\n",
    "    fake = torch.zeros([len(powers), *vox.shape[1:]])\n",
    "    fake_mu = torch.zeros_like(fake)\n",
    "    fake_sigma = torch.zeros_like(fake)\n",
    "    \n",
    "    for i in range(len(powers)):\n",
    "        data = {'mesh_semantics': vox[0],\n",
    "                'power': n_samples*[powers[i]],\n",
    "                'frames': n_samples*[frames[i]]}\n",
    "        data = tensorize_dict(data)\n",
    "        \n",
    "        fake[i], fake_mu[i], fake_sigma[i] = model(data,'inference')\n",
    "    return fake, fake_mu, fake_sigma\n",
    "\n",
    "def histogram_intersection(fake, real, bins=20):\n",
    "    sm_ls = []\n",
    "    \n",
    "    for i in range(len(real)):\n",
    "        d1 = fake[i]\n",
    "        d2 = real[i]\n",
    "        \n",
    "        h1 = np.histogram(d1, bins=20, range=(0,1))[0]/len(d1)\n",
    "        h2 = np.histogram(d2, bins=20, range=(0,1))[0]/len(d2)\n",
    "\n",
    "        sm = 0\n",
    "        for i in range(bins):\n",
    "            sm += min(h1[i], h2[i])\n",
    "        sm_ls += [sm]\n",
    "    return sm_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_opt = Options('options/test_options.yaml')\n",
    "org_opt.initialize()\n",
    "org_opt.train_mode = 'GAN'\n",
    "org_opt.batch_size = org_opt.how_many\n",
    "dataloader, dataset = data.create_dataloader(org_opt)\n",
    "\n",
    "mesh_files = dataset.mesh_paths[:org_opt.how_many]\n",
    "data = next(iter(dataloader))\n",
    "patches = data['mesh_slices'][:org_opt.how_many,0]\n",
    "\n",
    "opt = deepcopy(org_opt)\n",
    "\n",
    "exp = 5\n",
    "inst = 1\n",
    "\n",
    "# load the dataset\n",
    "opt = deepcopy(org_opt)\n",
    "opt.name += '(exp'+str(exp)+')'#(inst'+str(inst)+')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = opt\n",
    "paired = True\n",
    "\n",
    "out_dir = opt.results_dir+opt.name+'/'\n",
    "z_pad = opt.delta_slice*(opt.in_Gslices//2)\n",
    "\n",
    "mkdir(out_dir)\n",
    "\n",
    "model = Pix2PixModel(opt)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_combs = np.asarray(list(itertools.product(opt.powers, opt.frames)))\n",
    "\n",
    "mesh_file = mesh_files[0]\n",
    "out_file = out_dir+Path(mesh_file).stem\n",
    "\n",
    "mesh = Mesh(mesh_file)\n",
    "mesh.scale_z(min(opt.mesh_res[1:])/opt.mesh_res[0])\n",
    "\n",
    "vox = mesh.voxelize(opt.mesh_res, z_pad, opt.max_xy_sz, opt.in_dim)\n",
    "if paired:\n",
    "    gt, dendrites = generate(vox, opt.sigmas, opt.background, opt.p_blobs, style_combs[:,0], style_combs[:,1])\n",
    "    \n",
    "z_ind = np.argmax(vox.sum(-1).sum(-1))\n",
    "\n",
    "vox_slice = vox[None, None, z_ind-z_pad:z_ind+z_pad+1]\n",
    "gt_slice = gt[:,:,z_ind-z_pad:z_ind+z_pad+1]\n",
    "dends_slice = dendrites[None, None, z_ind-z_pad:z_ind+z_pad+1]\n",
    "background_slice = ~dends_slice\n",
    "\n",
    "block = [1, *opt.crop_xy_sz]\n",
    "vox_patches = sample_patches(vox_slice[0], block, block)\n",
    "gt_patches = sample_patches(gt_slice[:,0], block, block)\n",
    "dend_patches = sample_patches(dends_slice[0], block, block).bool()\n",
    "background_patches = ~dend_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake, fake_mu, fake_sigma = test(model, vox_patches, style_combs[:,0], style_combs[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_sz = np.ceil((np.array(opt.sigmas)*3*2+1)).astype(int)\n",
    "gauss_sz += 1-gauss_sz%2\n",
    "if opt.in_dim=='2D':\n",
    "    gauss_sz[0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vox_patches[0,:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample_patches(vox_patches[0,:,0], gauss_sz, (1,1,1), padding=False)\n",
    "X = X.view(-1, np.prod(gauss_sz)).T\n",
    "\n",
    "Y = fake.view(len(style_combs),-1)\n",
    "\n",
    "Ypred = no_padding((fake*dend_patches)[:,:,:,0], gauss_sz)\n",
    "Ypred = Ypred.reshape(len(style_combs),-1).T\n",
    "\n",
    "Y = no_padding((gt_patches*dend_patches)[:,:,:,0], gauss_sz)\n",
    "Y = Y.reshape(len(style_combs),-1).T\n",
    "\n",
    "inv_covar = torch.inverse(torch.matmul(X,X.T))\n",
    "cross_corr_pred = torch.matmul(X,Ypred)\n",
    "cross_corr = torch.matmul(X,Y)\n",
    "\n",
    "w_pred = torch.matmul(inv_covar,cross_corr_pred)\n",
    "w_pred = (w_pred/w_pred.sum(0)).T\n",
    "\n",
    "w = torch.matmul(inv_covar,cross_corr)\n",
    "w = (w/w.sum(0)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_gauss = ((w-w_pred)**2).mean(1)\n",
    "hist_dendrites = histogram_intersection(fake[:,dend_patches[0]],gt_patches[:,dend_patches[0]])\n",
    "hist_background = histogram_intersection(fake[:,background_patches[0]],gt_patches[:,background_patches[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powers = np.linspace(min(opt.powers), max(opt.powers), num=opt.n_interp)\n",
    "frames = opt.n_interp*[min(opt.frames)]\n",
    "\n",
    "fake, fake_mu, fake_sigma = test(model, vox_patches, powers, frames)\n",
    "avgs = fake.mean([-1,-2,-3,-4,-5])\n",
    "_, _, r_value, _, _ = stats.linregress(powers, avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powers = opt.n_frames*[max(opt.powers)]\n",
    "frames = opt.n_frames*[min(opt.frames)]\n",
    "\n",
    "fake, fake_mu, fake_sigma = test(model, vox_patches, powers, frames)\n",
    "var = fake[:,dend_patches[0]].var(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake[:,dend_patches[0]].var(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_grid(model, vox, file, opt, gt=False):\n",
    "    to_grid = partial(vutils.save_image, nrow=len(opt.frames), padding=2, normalize=False, pad_value=1.0)\n",
    "    \n",
    "    style_combs = np.asarray(list(itertools.product(opt.powers, opt.frames)))\n",
    "    input = np.concatenate(len(style_combs)*[vox[None]])\n",
    "    z_ind = np.argmax(vox.sum(-1).sum(-1))\n",
    "\n",
    "    data = {'mesh_semantics': input[None],\n",
    "            'power': style_combs[:,0],\n",
    "            'frames': style_combs[:,1]}\n",
    "    data = tensorize_dict(data)\n",
    "\n",
    "    if gt:\n",
    "        fake = generate(vox, opt.sigmas, opt.background, opt.p_blobs, style_combs[:,0], style_combs[:,1])\n",
    "        to_grid(fake[:,:,z_ind], file+'_fake.png')\n",
    "        return\n",
    "\n",
    "    fake, fake_mu, fake_sigma = model(data,'inference')\n",
    "\n",
    "    to_grid(fake[:,:,z_ind], file+'_fake.png')\n",
    "    to_grid(fake_mu[:,:,z_ind], file+'_mu.png')\n",
    "    to_grid(fake_sigma[:,:,z_ind], file+'_sigma.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(powers),**vox_patches.shape[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,2,3,4,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(x)//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
