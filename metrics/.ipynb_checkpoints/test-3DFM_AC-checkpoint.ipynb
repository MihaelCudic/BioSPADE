{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Code to perform evaluation on 3DFM_AC dataset\n",
    "'''\n",
    "\n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import itertools\n",
    "import torch\n",
    "import tifffile\n",
    "import random\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "import cv2\n",
    "\n",
    "from scipy.ndimage import uniform_filter\n",
    "\n",
    "import data\n",
    "from data.sampler.fmAC3D_sampler import FMAC3DSampler\n",
    "from options.options import Options\n",
    "from util.mesh_handler import *\n",
    "from util.util import *\n",
    "from metric_funcs import *\n",
    "\n",
    "from models.biospade_model import BioSPADEModel\n",
    "from models.segment_model import SegmentModel\n",
    "\n",
    "import models.networks as networks\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "name = 'FM3D_AC' # Name of experiments\n",
    "\n",
    "# Generate fake images\n",
    "def forward(vox, powers, frames, z_pos, is_cycle=False):\n",
    "    n_samples = vox.shape[0]\n",
    "    in_Dslices = vox.shape[-3]-org_opt.in_Gslices+1\n",
    "\n",
    "    fake = torch.zeros([len(powers), n_samples, 1, in_Dslices, *vox.shape[-2:]])\n",
    "    fake_mu = torch.zeros_like(fake)\n",
    "    \n",
    "    for i in range(len(powers)):\n",
    "        data = {'mesh_semantics': vox,\n",
    "                'power': n_samples*[powers[i]],\n",
    "                'frames': n_samples*[frames[i]],\n",
    "                'z_pos': z_pos}\n",
    "        \n",
    "        if is_cycle:\n",
    "            for z in range(0, in_Dslices-1, org_opt.in_Dslices):\n",
    "                data['mesh_semantics'] = vox[:,:,z:z+org_opt.in_Gslices+org_opt.in_Dslices-1]\n",
    "                data = tensorize_dict(data)\n",
    "                \n",
    "                model_Cycle.set_input(data)\n",
    "                fake_ = model_Cycle.forward(True)\n",
    "                fake[i,:,:,z:z+org_opt.in_Dslices] = torch.relu(fake_[:,None])\n",
    "        else:\n",
    "            data = tensorize_dict(data)\n",
    "            fake[i], fake_mu[i] = model_Gan(data,'inference')\n",
    "    return fake.cpu().numpy(), fake_mu.cpu().numpy()\n",
    "\n",
    "# Code to Generate Testing Data\n",
    "def get_data(loader):\n",
    "    sample = next(iter(loader))\n",
    "    \n",
    "    stack_ = sample['real_stack'].numpy()[0]\n",
    "    org_stack = sample['real_stack'].reshape((-1,*stack_.shape[1:])).numpy()\n",
    "    \n",
    "    vox_ = sample['mesh_semantics'].numpy()[0]\n",
    "    vox = sample['mesh_semantics'].reshape((-1,*vox_.shape[1:])).numpy()\n",
    "    \n",
    "    z_sz = vox.shape[-3]-2*sampler.z_pad\n",
    "    xy_sz = vox.shape[-2:]\n",
    "\n",
    "    gt = sample['real_slices'].reshape((-1,z_sz, *xy_sz)).numpy()\n",
    "    mask = np.zeros_like(gt)\n",
    "    for i, gt_ in enumerate(gt):\n",
    "        mask[i] = uniform_filter(gt_, 5)>1e-5\n",
    "\n",
    "    z_pos = sample['z_pos'].reshape((-1,)).numpy()\n",
    "    \n",
    "    stack_shape = vox.shape\n",
    "    stack = np.zeros((len(style_combs), stack_shape[0], stack_shape[1]-2*sampler.z_pad, *xy_sz))\n",
    "    for i, style in enumerate(style_combs):\n",
    "        pow_ = int(style[0])\n",
    "        frame_ = int(style[1])\n",
    "        stack_ = org_stack[:,pow_,:,:frame_].mean(2)\n",
    "        stack[i] = stack_[:]\n",
    "        \n",
    "    return stack, gt, mask, vox, z_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Parameters\n",
    "\n",
    "org_opt = Options('options/test_options.yaml', 'fmAC3D')\n",
    "org_opt.initialize()\n",
    "\n",
    "org_opt.train_mode = 'SEG'\n",
    "org_opt.dataset_mode = 'fmAC3D'\n",
    "org_opt.name = name\n",
    "\n",
    "# Create loader for standard eval metrics (data taken from training dataset)\n",
    "org_opt.batch_size = 13 # batch size\n",
    "org_opt.samples_per_instance = 8 # samples per loaded mesh\n",
    "\n",
    "dataloader, dataset = data.create_dataloader(org_opt,'train')\n",
    "\n",
    "# Create loader for segmentation metrics (data taking from testing dataset)\n",
    "org_opt.batch_size = 4\n",
    "org_opt.samples_per_instance = 52\n",
    "org_opt.in_Dslices = org_opt.in_Sslices\n",
    "org_opt.prob_new_mesh = 0\n",
    "dataloader_seg, dataset_seg = data.create_dataloader(org_opt,'test')\n",
    "\n",
    "sac_files = dataset.stack_paths\n",
    "gt_files = dataset.gt_paths\n",
    "mesh_files = dataset.mesh_paths\n",
    "\n",
    "z_pad = org_opt.delta_slice*(org_opt.in_Gslices//2)\n",
    "sampler = FMAC3DSampler(org_opt)\n",
    "\n",
    "style_combs = np.asarray(list(itertools.product(org_opt.powers, org_opt.frames)))\n",
    "pow_inds = []\n",
    "for i in range(5):\n",
    "    pow_inds += list(np.array([0,3,7])+8*i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate testing data for texture eval\n",
    "\n",
    "stack, gt, real_mask, vox, z_pos = get_data(dataloader)\n",
    "\n",
    "fake_mask = np.zeros_like(gt)\n",
    "for i, gt_ in enumerate(vox):\n",
    "    fake_mask[i] = uniform_filter(gt_[3:-3]/vox.max(), 3)>1e-5\n",
    "\n",
    "avg_real = stack[pow_inds]\n",
    "text_real = blur_all(avg_real)\n",
    "\n",
    "\n",
    "# Generate testing data for segmentation eval\n",
    "\n",
    "seg_stack, seg_gt, _, _, seg_z_pos = get_data(dataloader_seg) # Might not fit in GPU, so segmentation eval must be done seperately\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Evaluation\n",
    "\n",
    "out_sz = (org_opt.number_of_experiments, len(style_combs))\n",
    "pow_out_sz = (org_opt.number_of_experiments, len(pow_inds))\n",
    "losses = {'NMSE': np.zeros(pow_out_sz),\n",
    "          'PSNR': np.zeros(out_sz),\n",
    "          'JSD': np.zeros(out_sz),\n",
    "          'GLCM': np.zeros(pow_out_sz),\n",
    "          'LBP': np.zeros(pow_out_sz),\n",
    "          'COOC': np.zeros(pow_out_sz),\n",
    "          'SEG': np.zeros([*out_sz, 3]),}\n",
    "\n",
    "real_auto = calc_auto(avg_real) # Calculate real auto_correlation\n",
    "real_LBP = calc_LBP(text_real,real_mask) # Calculate real LBP\n",
    "real_GLCM = calc_GLCM(text_real,real_mask) # Calculate real GLCM\n",
    "real_COOC = calc_COOC(text_real, real_mask>.5) # Calculate real COOC\n",
    "\n",
    "calc_seg=False\n",
    "for exp in range(0,org_opt.number_of_experiments):\n",
    "    # Get experiment details\n",
    "    opt = deepcopy(org_opt)\n",
    "    exp_str = ''\n",
    "    if not org_opt.run_all:\n",
    "        exp_str = '(exp'+str(exp)+')'\n",
    "        opt.set_experiment(exp)\n",
    "    opt.name = org_opt.name+exp_str\n",
    "\n",
    "    # Calculate Segmentation results\n",
    "    if calc_seg:\n",
    "        for i in range(3):\n",
    "            opt.seg_instance = i\n",
    "            model_Seg = SegmentModel(opt)\n",
    "            model_Seg.eval()\n",
    "\n",
    "            acc = SEG(model_Seg, seg_stack[:,:,None], seg_gt, style_combs[:,0], style_combs[:,1], seg_z_pos, )\n",
    "            losses['SEG'][exp,:,i] = acc\n",
    "    \n",
    "    # Load model\n",
    "    print('Evaluating:', opt.name)\n",
    "    model_Gan = BioSPADEModel(opt)\n",
    "    model_Gan.eval()\n",
    "\n",
    "    # Generate Data\n",
    "    fake, channels = forward(vox[:,None], style_combs[:,0], style_combs[:,1], z_pos)\n",
    "    avg_fake = fake[pow_inds,:,0]\n",
    "    text_fake = blur_all(avg_fake)\n",
    "    \n",
    "    # Evaluate\n",
    "    fake_auto = calc_auto(avg_fake)\n",
    "    fake_LBP = calc_LBP(text_fake, fake_mask) # Use fake_mask as we only want to compute metric around dendrites\n",
    "    fake_GLCM = calc_GLCM(text_fake, fake_mask) # Use fake_mask as we only want to compute metric around dendrites\n",
    "    fake_COOC = calc_COOC(text_fake, fake_mask>.5) # Use fake_mask as we only want to compute metric around dendrites\n",
    "    \n",
    "    losses['NMSE'][exp] = MSE(fake_auto, real_auto, normalize=True) # Compute NMSE of autocorrelation\n",
    "    losses['GLCM'][exp] = MSE(fake_GLCM, real_GLCM,axis=(1,2,3,4)) # Compute MSE of GLCM\n",
    "    losses['LBP'][exp] = mult_JSDs(fake_LBP, real_LBP) # Compute JSD of LBP\n",
    "    losses['COOC'][exp] = MSE(fake_COOC, real_COOC, axis=(1,2,3,4,5,6)) # Compute MSE of COOC\n",
    "    losses['JSD'][exp] = compare_hist(fake, stack) # Compute JSD of pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Results (Note there will be variance trial to trail since we are sampling patches)\n",
    "\n",
    "keys = ['NMSE', 'LBP', 'GLCM', 'COOC', 'JSD', 'SEG']\n",
    "scale = {'NMSE': 1e1, 'GLCM': 1e8, 'LBP': 1e3, 'PSNR':1e1, 'JSD': 1e2, 'COOC':1e8, 'Frangi':1e5, 'SEG': 100}\n",
    "\n",
    "ln = ''\n",
    "for key in keys:\n",
    "    ln += key+' & '\n",
    "print(ln)\n",
    "\n",
    "for i_loss in range(org_opt.number_of_experiments):\n",
    "    ln = ''\n",
    "    for key in keys:\n",
    "        val = losses[key][i_loss].mean()\n",
    "        if key == 'SEG':\n",
    "            val = losses[key][i_loss].mean(0).mean(0)\n",
    "            var = losses['SEG'][i_loss].mean(0).std(0)\n",
    "            ln += '%0.3f +/- %0.3f' % (val*scale['SEG'], var*scale['SEG'])\n",
    "        else:\n",
    "            ln += '%0.3f ' % (val*scale[key])\n",
    "    print(ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
