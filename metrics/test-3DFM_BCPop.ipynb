{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Code to perform evaluation on 3DFM_BCPop dataset\n",
    "'''\n",
    "\n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import itertools\n",
    "import torch\n",
    "import tifffile\n",
    "\n",
    "import cv2\n",
    "\n",
    "from scipy.ndimage import uniform_filter\n",
    "\n",
    "import data\n",
    "from data.sampler.fmBCPop3D_sampler import FMBCPop3DSampler\n",
    "from options.options import Options\n",
    "from util.util import *\n",
    "from metric_funcs import *\n",
    "\n",
    "from models.biospade_model import BioSPADEModel\n",
    "from models.segment_model import SegmentModel\n",
    "\n",
    "import models.networks as networks\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "name = 'FM3D_BCPop' # Name of experiments\n",
    "pxs = 512 # xy size of patch to sample\n",
    "\n",
    "# Generate fake images\n",
    "def forward(vox, powers, frames, z_pos, is_cycle=False):\n",
    "    n_samples = vox.shape[1]\n",
    "    in_Dslices = vox.shape[-3]-org_opt.in_Gslices+1\n",
    "    in_Dslices_org = 4\n",
    "\n",
    "    fake = torch.zeros([len(powers), n_samples, 1, in_Dslices, *vox.shape[-2:]])\n",
    "    fake_mu = torch.zeros_like(fake)\n",
    "    \n",
    "    for i in range(len(powers)):\n",
    "        data = {'mesh_semantics': vox,\n",
    "                'real_semantics': vox,\n",
    "                'power': n_samples*[powers[i]],\n",
    "                'frames': n_samples*[frames[i]],\n",
    "                'z_pos': z_pos}\n",
    "        \n",
    "        if is_cycle:\n",
    "            for z in range(0, in_Dslices-1, in_Dslices_org):\n",
    "                data['mesh_semantics'] = vox[:,:,z:z+org_opt.in_Gslices+in_Dslices_org-1]\n",
    "                data['real_semantics'] = data['mesh_semantics']\n",
    "                data['z_pos'] = np.asarray(z_pos)+z*org_opt.delta_z\n",
    "                data = tensorize_dict(data)\n",
    "                model_Cycle.set_input(data)\n",
    "                fake_ = model_Cycle.forward(True)\n",
    "                fake[i,:,:,z:z+in_Dslices_org] = fake_[:,None]\n",
    "                fake = torch.relu(fake)\n",
    "        else:\n",
    "            data = tensorize_dict(data)\n",
    "            fake[i], fake_mu[i] = model_Gan(data,'inference')\n",
    "    return fake.cpu().numpy(), fake_mu.cpu().numpy()\n",
    "\n",
    "# Generate testing data\n",
    "def get_data(loader):\n",
    "    data_i = next(iter(dataloader))\n",
    "\n",
    "    real_stack = data_i['real_stack']\n",
    "    avg_real = data_i['real_stack'].numpy()\n",
    "    gt = data_i['real_semantics'].numpy()\n",
    "    z_pos = data_i['z_pos'].numpy()\n",
    "\n",
    "    mask = np.zeros_like(gt)\n",
    "    for i in range(mask.shape[1]):\n",
    "        mask[:,i] = uniform_filter(gt[:,i], 5)>1e-5\n",
    "        \n",
    "    real_stack = real_stack.reshape(1,8*9,4,pxs,pxs)\n",
    "    target = gt[:,:,4:-4].reshape(1,8*9,4,pxs,pxs)\n",
    "\n",
    "    seg_z_pos = np.zeros((9*len(z_pos[0])))\n",
    "    for i, z_pos_ in enumerate(z_pos[0]):\n",
    "        seg_z_pos[i*9:(i+1)*9] = np.asarray(range(9))*.4+z_pos_\n",
    "        \n",
    "    return real_stack, avg_real, gt, target, mask, z_pos, seg_z_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/cudicm2/Documents/Data/BipolarPopulation/Stack/Stack1_Laser8.tif', '/home/cudicm2/Documents/Data/BipolarPopulation/Stack/Stack2_Laser8.tif', '/home/cudicm2/Documents/Data/BipolarPopulation/Stack/Stack3_Laser8.tif']\n",
      "stack dataset [FMBCPop3DDataset] of size 16 was created\n",
      "mesh dataset [FMBCPop3DDataset] of size 16 was created\n"
     ]
    }
   ],
   "source": [
    "data_name = 'fmBCPop3D'\n",
    "\n",
    "org_opt = Options('options/test_options.yaml', data_name)\n",
    "org_opt.initialize()\n",
    "\n",
    "org_opt.train_mode = 'SEG'\n",
    "org_opt.dataset_mode = data_name\n",
    "org_opt.name = name\n",
    "org_opt.nThreads = 1\n",
    "\n",
    "org_opt.batch_size = 1\n",
    "org_opt.samples_per_instance = 8\n",
    "org_opt.crop_xy_sz = [pxs,pxs]\n",
    "org_opt.in_Dslices = 36\n",
    "\n",
    "style_combs = np.asarray(list(itertools.product(org_opt.powers, org_opt.frames)))\n",
    "\n",
    "dataloader, dataset = data.create_dataloader(org_opt,'train')\n",
    "real_stack, avg_real, gt, target, mask, z_pos, _ = get_data(dataloader)\n",
    "\n",
    "do_seg = False\n",
    "if do_seg: # Might not be able to fit both loaders on CPU so have to be done seperately\n",
    "    segloader, seg_dataset = data.create_dataloader(org_opt,'valid')\n",
    "    seg_real_stack, seg_avg_real, seg_gt, seg_target, seg_mask, seg_z_pos = get_data(segloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "text_real = blur_all(avg_real)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "real_LBP = calc_LBP(text_real,mask[0,:,4:-4]) # Compute real LBP\n",
    "print('LBP Done', time.time()-start_time)\n",
    "real_GLCM = calc_GLCM(text_real,mask[0,:,4:-4]) # Compute real GLCM\n",
    "print('GLCM Done', time.time()-start_time)\n",
    "real_COOC = calc_COOC(text_real, mask[0,:,4:-4]>.5) # Compute real COOC\n",
    "print('COOC Done', time.time()-start_time)\n",
    "\n",
    "out_sz = (org_opt.number_of_experiments, 1)\n",
    "pow_out_sz = (org_opt.number_of_experiments+1, len(org_opt.powers))\n",
    "losses = {'MSE': np.zeros(pow_out_sz),\n",
    "          'NMSE': np.zeros(pow_out_sz),\n",
    "          'PSNR': np.zeros(out_sz),\n",
    "          'JSD': np.zeros(out_sz),\n",
    "          'GLCM': np.zeros(pow_out_sz),\n",
    "          'LBP': np.zeros(pow_out_sz),\n",
    "          'COOC': np.zeros(pow_out_sz),\n",
    "          'SEG': np.zeros([*out_sz, 3]),}\n",
    "\n",
    "for exp in range(0,org_opt.number_of_experiments):\n",
    "    fake_exp = np.zeros(avg_real[:,:,None].shape)\n",
    "\n",
    "    # Get experiment details\n",
    "    opt = deepcopy(org_opt)\n",
    "    exp_str = ''\n",
    "    if not org_opt.run_all:\n",
    "        exp_str = '(exp'+str(exp)+')'\n",
    "        opt.set_experiment(exp)\n",
    "    opt.name = org_opt.name+exp_str\n",
    "    opt.paired_translation = False\n",
    "\n",
    "    # Calculate Segmentation results\n",
    "    if do_seg:\n",
    "        for i in range(3):\n",
    "            opt.seg_instance = i\n",
    "            model_Seg = SegmentModel(opt)\n",
    "            model_Seg.eval()\n",
    "            acc = SEG(model_Seg, seg_real_stack[:,:,None], seg_target, style_combs[:,0], style_combs[:,1], seg_z_pos, batch_sz=16)\n",
    "            losses['SEG'][exp,:,i] = acc\n",
    "    \n",
    "    # Patch too large for GPU. Split 4 times and send smaller subpatches to GPU individually to create entire fake patch\n",
    "    for i in range(4): \n",
    "        gt_ = gt[:,i*org_opt.samples_per_instance//4:(i+1)*org_opt.samples_per_instance//4]\n",
    "        z_pos_ = z_pos[:,i*org_opt.samples_per_instance//4:(i+1)*org_opt.samples_per_instance//4]\n",
    "\n",
    "        model_Gan = BioSPADEModel(opt)\n",
    "        model_Gan.eval()\n",
    "        fake,_ = forward(gt_, style_combs[:,0], style_combs[:,1], z_pos_)\n",
    "            \n",
    "        fake_exp[:,i*org_opt.samples_per_instance//4:(i+1)*org_opt.samples_per_instance//4] = fake\n",
    "    avg_fake = fake_exp\n",
    "\n",
    "    avg_fake = avg_fake[:,:,0]\n",
    "    text_fake = blur_all(avg_fake)\n",
    "    fake = fake[:,:,0]\n",
    "    \n",
    "    # Evaluate\n",
    "    fake_LBP = calc_LBP(text_fake, mask[0,:,4:-4]) # Use mask as we only want to compute metric around dendrites\n",
    "    fake_GLCM = calc_GLCM(text_fake, mask[0,:,4:-4]) # Use mask as we only want to compute metric around dendrites\n",
    "    fake_COOC = calc_COOC(text_fake, mask[0,:,4:-4]>.5) # Use mask as we only want to compute metric around dendrites\n",
    "    \n",
    "    losses['MSE'][exp] = MSE(fake_exp[:,:,0]*gt[:,:,4:-4], avg_real[0]*gt[0,:,4:-4]) # Compute MSE\n",
    "    losses['GLCM'][exp] = MSE(fake_GLCM, real_GLCM, axis=(1,2,3,4)) # Compute MSE of GLCM\n",
    "    losses['LBP'][exp] = mult_JSDs(fake_LBP, real_LBP) # Compute JSD of LBP\n",
    "    losses['COOC'][exp] = MSE(fake_COOC, real_COOC, axis=(1,2,3,4,5,6)) # Compute MSE of COOC\n",
    "    losses['JSD'][exp] = compare_hist(fake, avg_real) # Compute JSD of pixels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print Results (Note there will be variance trial to trail since we are sampling patches)\n",
    "\n",
    "keys = ['MSE', 'LBP', 'GLCM', 'COOC', 'JSD', 'SEG']\n",
    "scale = {'MSE': 1e3, 'NMSE': 1e1, 'GLCM': 1e8, 'LBP': 1e3, 'PSNR':1e1, 'JSD': 1e2, 'COOC':1e8, 'Frangi':1e5, 'SEG': 100}\n",
    "\n",
    "ln = ''s\n",
    "for key in keys:\n",
    "    ln += key+' & '\n",
    "print(ln)\n",
    "\n",
    "for i_loss in range(org_opt.number_of_experiments):\n",
    "    ln = ''\n",
    "    for key in keys:\n",
    "        val = losses[key][i_loss].mean()\n",
    "        if key == 'SEG':\n",
    "            val = losses[key][i_loss].mean(0).mean(0)\n",
    "            var = losses['SEG'][i_loss].mean(0).std(0)\n",
    "            ln += '%0.3f +/- %0.3f' % (val*scale['SEG'], var*scale['SEG'])\n",
    "        else:\n",
    "            ln += '%0.3f ' % (val*scale[key])\n",
    "    print(ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
